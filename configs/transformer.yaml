vqvae_model_path: results/srgan1_20JUL/vqvae/model.th
folder: results/srgan1_27JUL/transformer
epochs: 1000
lr: 0.0005
weight_decay: 0
learning_rate_scheduler: poly
batch_size: 8
num_workers: 0
gpus: 1
distributed_backend: horovod
nb_examples: null
save_every: 1
generate: false
hidden_size: 768
num_hidden_layers: 8
num_attention_heads: 8
intermediate_size: 6144
hidden_dropout_prob: 0
attention_dropout_prob: 0
gradient_clip_val: 1 #0=don't clip
warmup_iter: 5000
fixed_encoder: true
